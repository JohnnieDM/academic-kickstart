+++
abstract = "Story-telling is a fundamental and prevalent aspect of human social behavior. In the wild, stories are told conversationally in social settings, often as a dialogue and with accompanying gestures and other nonverbal behavior. This paper presents a new corpus, the STORY DIALOGUE WITH GESTURES (SDG) corpus, consisting of 50 personal narratives regenerated as dialogues, complete with annotations of gesture placement and accompanying gesture forms. The corpus includes dialogues generated by human annotators, gesture annotations on the human generated dialogues, videos of story dialogues generated from this representation, video clips of each gesture used in the gesture annotations, and annotations of the original personal narratives with a deep representation of story called a STORY INTENTION GRAPH. Our long term goal is the automatic generation of story co-tellings as animated dialogues from the STORY INTENTION GRAPH. We expect this corpus to be a useful resource for researchers interested in natural language generation, intelligent virtual agents, generation of nonverbal behavior, and story and narrative representations."
authors = ["Zhichao Hu", "Michelle Dick", "Johnnie C-N. Chang", "Kevin Bowden", "Michael Neff", "Jean E. Fox Tree", "Marilyn Walker"]
date = "2016-05-23"
image = ""
image_preview = ""
math = false
publication = "Language Resources and Evaluation Conference 2016"
title = "A Corpus of Gesture-Annotated Dialogues for Monologue-to-Dialogue Generation from Personal Narratives"
url_code = ""
url_dataset = ""
url_pdf = "pdf/my-paper-name.pdf"
url_project = ""
url_slides = ""
url_video = ""
+++
